{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2d6f1bf97fc4c90a5d9a2ffaaa386ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55ece4581c07484b914599e3d8b48559",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5b18dd2316840ea98009608e8f10cbe",
              "IPY_MODEL_1a2ad74aed444b41acb58992b8a493ea"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "55ece4581c07484b914599e3d8b48559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a5b18dd2316840ea98009608e8f10cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eac62f2c629d480e9b37fdfbf47de416",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad8138566b684bfb9e0eaa87ee0701a3"
          },
          "model_module_version": "1.5.0"
        },
        "1a2ad74aed444b41acb58992b8a493ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_864c372fde8a4281837497b495478aae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 78242190.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5fa90f4ee4b49ac9f0794e859ddf7a1"
          },
          "model_module_version": "1.5.0"
        },
        "eac62f2c629d480e9b37fdfbf47de416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ad8138566b684bfb9e0eaa87ee0701a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "864c372fde8a4281837497b495478aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f5fa90f4ee4b49ac9f0794e859ddf7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5K5wt_7DM_3"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9rFe0TCDM_-"
      },
      "source": [
        "## CompositeLayer is an nn.Module with the following layers (in order):\n",
        "\n",
        "### 1. BatchNorm2d with default parameters\n",
        "### 2. ReLU\n",
        "### 3. Conv2d with kernel_size=1, stride=1, bias=False, all others default values\n",
        "### 4. BatchNorm2d with default parameters\n",
        "### 5. ReLU\n",
        "### 6. Conv2d with kernel_size=3, stride=1, padding=1, bias=False, all others default values\n",
        "\n",
        "#### These layers are connected in a sequential order (i.e., 1-2-3-4-5-6)\n",
        "\n",
        "## Fill the blanks marked by \"##ToAdd:\" in the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCzgWgnYDM__"
      },
      "source": [
        "class CompositeLayer(nn.Module):\n",
        "    def __init__(self, num_input_features, num_hidden_features, num_output_features):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            num_input_features: int, num_features for the first BatchNorm2d\n",
        "            num_hidden_features: int, out_channels for the first Conv2d\n",
        "            num_output_features: int, out_channels for the second Conv2d\n",
        "        \"\"\"\n",
        "        super(CompositeLayer, self).__init__()\n",
        "        ##ToAdd: add the layers specified above\n",
        "        self.norm1 = nn.BatchNorm2d(num_features=num_input_features)##ToAdd: layer BatchNorm2d with default parameters\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_channels=num_input_features, out_channels=num_hidden_features, kernel_size=1, padding=1, stride=1, bias=False)\n",
        "        self.norm2 = nn.BatchNorm2d(num_features=num_hidden_features)##ToAdd: layer BatchNorm2d with default parameters\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_hidden_features, out_channels=num_output_features, kernel_size=3, padding=1, stride=1,bias=False)\n",
        "        ##EndAdd\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: a torch.Tensor or a list of torch.Tensor\n",
        "        \"\"\"\n",
        "        if isinstance(inputs, list):\n",
        "            inputs = torch.cat(inputs, 1)\n",
        "        ##ToAdd: forward pass from inputs to outputs\n",
        "            out = self.conv1(inputs)\n",
        "            out = self.relu(self.norm1(out))\n",
        "            out = self.conv2(out)\n",
        "            out = self.relu(self.norm2(out))\n",
        "            out = out.squeeze()\n",
        "        ##EndToAdd\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir6bwzO4DNAG"
      },
      "source": [
        "## Block consists of a number (argument `num_layers`) of CompositeLayer defined above:\n",
        "### To illustrate how it works, let's set `num_layers=4` for a Block model.\n",
        "### Then it will have 4 CompositeLayer. Let's name them as `layer1`, `layer2`, `layer3`, and `layer4`.\n",
        "### The input of `layer1` is provided as `init_features` in the `forward` function defined below.\n",
        "### `init_features` and the output of `layer1` will be concatenated together at the channel dimension as the input of `layer2`\n",
        "## `init_features`, the output of `layer1` and the output of `layer2` concatenated together at the channel dimension (dim=1) will be the input of `layer3`.\n",
        "## `init_features`, the outputs of `layer1`, `layer2`, and `layer3` concatenated together at the channel dimension (dim=1) will be the input of `layer4`.\n",
        "## So the input of `layer{i}` is the concatenated outputs of all its previous layers from `layer1` until `layer{i-1}` as well as `init_features`\n",
        "## The model `forward` function returns the `init_features` and ALL OUTPUTS of all layers concatenated together at the channel dimension (dim=1)\n",
        "\n",
        "\n",
        "## Fill the blanks marked by \"##ToAdd:\" in the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJUGVW34DNAH"
      },
      "source": [
        "class Block(nn.ModuleDict):\n",
        "    def __init__(self, num_layers, num_input_features, num_hidden_features, num_output_features):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            num_layers: int, how many CompositeLayer are included\n",
        "            num_input_features: int, num_input_features for the FIRST CompositeLayer (YOU NEED TO CALCULATE the num_input_features for all other CompositeLayer)\n",
        "            num_hidden_features: int, num_hidden_features for every CompositeLayer\n",
        "            num_output_features: int, num_output_features for every CompositeLayer\n",
        "        \"\"\"\n",
        "        super(Block, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            ##ToAdd: Add a number of CompositeLayer. Hint: define a CompositeLayer with proper arguments, and use add_module function to add it to self\n",
        "            CompositeLayer=Block(i,num_input_features,num_hidden_features,num_output_features)\n",
        "            self.add_module('layer%d' % (i + 1), CompositeLayer)\n",
        "\n",
        "            ##EndAdd\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            init_features: torch.Tensor, the input of the first CompositeLayer\n",
        "        \"\"\"\n",
        "        features = [init_features]\n",
        "        ##ToAdd: forward pass. Hint: Append the output of each layer to features one at a time until the last layer\n",
        "        for l in range('layer%d' % (i + 1)):\n",
        "            out = self.layer(l)(features)\n",
        "            features.append(out)\n",
        "\n",
        "        ##EndAdd\n",
        "        return torch.cat(features, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6mbNJDDNAM"
      },
      "source": [
        "## ConvPool is nn.Sequential with the following layers (in order):\n",
        "\n",
        "### 1. BatchNorm2d with default parameters\n",
        "### 2. ReLU\n",
        "### 3. Conv2d with kernel_size=1, stride=1, bias=False, all others default values\n",
        "### 4. AvgPool2d with kernel_size=2, stride=2, all others default values\n",
        "\n",
        "#### For a subclass of nn.Sequential, you only need to define `__init__` (the `forward` function is already defined in nn.Sequential)\n",
        "\n",
        "## Fill the blanks marked by \"##ToAdd:\" in the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqknCNh2DNAN"
      },
      "source": [
        "class ConvPool(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            num_input_features: int, num_features for the BatchNorm2d layer\n",
        "            num_output_features: int, out_channels for the Conv2d layer\n",
        "        \"\"\"\n",
        "        super(ConvPool, self).__init__()\n",
        "        ##ToAdd: add the layers specified above; hint: use add_module function in nn.Sequential class\n",
        "        self.add_module('norm1',nn.BatchNorm2d(num_features=num_input_features))##ToAdd: layer BatchNorm2d with default parameters\n",
        "        self.add_module('relu1',nn.ReLU(inplace=True))\n",
        "        self.add_module('conv1' ,nn.Conv2d(in_channels=num_input_features, out_channels=num_output_features, kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "        ##EndAdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrHZPtjADNAT"
      },
      "source": [
        "## BlockNet is more complex. It consists multiple Block layers (Note each Block layer consists of multiple CompositeLayer), specified by `block_config`.\n",
        "## The model architecture is as follows:\n",
        "### First convolutional layer (already defined for you) to process the input\n",
        "### A number of Block layers and ConvPool layers you need to add\n",
        "### Final layers such as AvgPool2d and Linear to predict the class labels (already defined for you)\n",
        "\n",
        "\n",
        "## Fill the blanks marked by \"##ToAdd:\" in the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqvrF2aDNAU"
      },
      "source": [
        "class BlockNet(nn.Module):\n",
        "    def __init__(self, block_config=(6, 12, 24, 16), num_init_features=64,\n",
        "                 num_hidden_features=128, num_output_features=32, num_classes=10):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            block_config: list of ints, how many layers in Block layer\n",
        "            num_init_features: int, num_input_features for the FIRST Block layer. (You need to calculate the num_input_features for all other Block layers)\n",
        "            num_hidden_features: int, num_hidden_features for ALL Block layers\n",
        "            num_output_features: int, num_output_features for ALL Block layers\n",
        "            num_classes: int, number of classes, out_features for the last Linear layer (already defined for you)\n",
        "        \"\"\"\n",
        "        super(BlockNet, self).__init__()\n",
        "\n",
        "        # First convolution already defined for you\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))]))\n",
        "\n",
        "        # A number of Block and ConvPool layers\n",
        "        num_features = num_init_features #num_features is used as the num_input_features for each Block layer\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            ##ToAdd: Define a Block layer with num_input_features=num_features\n",
        "            block = Block(num_layers=num_layers, num_input_features=num_features, num_hidden_features=num_hidden_features,\n",
        "                          num_output_features=num_output_features)\n",
        "            ##EndAdd\n",
        "            self.features.add_module(f'block{i+1}', block)\n",
        "\n",
        "            ##ToAdd: calculate num_features as the output of the Block layer\n",
        "            num_features = num_features+ num_output_features*num_layers\n",
        "            ## EndAdd\n",
        "\n",
        "            if i != len(block_config) - 1:\n",
        "                # All Block layers Except the last one is followed by a ConvPool layer\n",
        "                # Important: ConvPool layer will reduce the number of features by half\n",
        "                ##ToAdd: add a ConvPool layer with num_input_features=num_features, num_output_features=num_features//2\n",
        "                convpool = ConvPool( num_input_features=num_features, num_output_features=num_features//2 )\n",
        "                ##EndAdd\n",
        "                self.features.add_module(f'convpool{i+1}', convpool)\n",
        "                # Here we update the num_features, which will be used for the next Block layer in this for loop\n",
        "                num_features = num_features // 2\n",
        "        # Final batch norm\n",
        "        self.features.add_module(f'norm{len(block_config)+1}', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRulChlkDNAa"
      },
      "source": [
        "## Well done!\n",
        "## You don't need to change the following cells. They are here for you to learn how to train a computer vision model in practice\n",
        "## You can also test your implemented BlockNet model using it\n",
        "## If you can build a good BlockNet model (change `block_config`, `num_init_features`, `num_hidden_features`, `num_output_features`) and train it well (change optimizer, learning rate, num_epochs, etc.), you will get some extra credit in case you haven't gotten a perfect score. You are highly recommended to do so!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EW1JfIEDNAb",
        "outputId": "706ce1ff-a889-4a23-fb5b-cbb5c4895a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f2d6f1bf97fc4c90a5d9a2ffaaa386ba",
            "55ece4581c07484b914599e3d8b48559",
            "a5b18dd2316840ea98009608e8f10cbe",
            "1a2ad74aed444b41acb58992b8a493ea",
            "eac62f2c629d480e9b37fdfbf47de416",
            "ad8138566b684bfb9e0eaa87ee0701a3",
            "864c372fde8a4281837497b495478aae",
            "f5fa90f4ee4b49ac9f0794e859ddf7a1"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainset, validationset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2d6f1bf97fc4c90a5d9a2ffaaa386ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKD1RMVoDNAg"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True, pin_memory=True, num_workers=4)\n",
        "validationloader = torch.utils.data.DataLoader(validationset, batch_size=1024,\n",
        "                                          shuffle=False, pin_memory=True, num_workers=4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1024,\n",
        "                                         shuffle=False, pin_memory=True, num_workers=4)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycAQNJUiDNAm",
        "outputId": "29a212a4-6644-487f-8584-332f4b65fba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "writer = SummaryWriter('runs/cifar10')\n",
        "model = BlockNet((2, 3), num_init_features=16, num_hidden_features=32, num_output_features=16, num_classes=10)\n",
        "writer.add_graph(model, torch.randn(1, 3, 32, 32))\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e718b0e9da1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs/cifar10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_init_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    953\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    954\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                             check_tolerance, strict, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b048a71f90e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d4a84df39085>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m##ToAdd: forward pass. Hint: Append the output of each layer to features one at a time until the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzFIoq9cDNAu"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = torch.nn.DataParallel(model).to(device)\n",
        "else:\n",
        "    model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def get_acc(model, loader):\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        for i, data in enumerate(loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            correct += (labels == outputs.argmax(dim=1).squeeze()).sum()\n",
        "        acc = float(correct) / len(loader.dataset)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV_XUupzDNAy",
        "outputId": "529b3052-6b6e-43ca-d0dd-daeee2ab2b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "num_epochs = 8\n",
        "eval_every = 100\n",
        "train_acc_his = []\n",
        "val_acc_his = []\n",
        "test_acc_his = []\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i+1) % eval_every == 0:\n",
        "            train_acc = get_acc(model, trainloader)\n",
        "            val_acc = get_acc(model, validationloader)\n",
        "            test_acc = get_acc(model, testloader)\n",
        "            train_acc_his.append(train_acc)\n",
        "            val_acc_his.append(val_acc)\n",
        "            test_acc_his.append(test_acc)\n",
        "            writer.add_scalar('train_acc', train_acc, len(train_acc_his))\n",
        "            writer.add_scalar('val_acc', val_acc, len(val_acc_his))\n",
        "            writer.add_scalar('test_acc', test_acc, len(test_acc_his))\n",
        "            print('[epoch %d, iter %d] train_acc: %.3f  val_acc: %.3f  test_acc: %.3f' %\n",
        "                  (epoch+1, i+1, train_acc, val_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8e5060df2489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b048a71f90e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-48c1590a3956>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m##ToAdd: forward pass. Hint: Append the output of each layer to features one at a time until the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m##for i in range(num_layers):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ndn9r4DNA2",
        "outputId": "f07d9ff5-8a7a-44d9-940f-c5cfe59ad193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(train_acc_his, 'ro-', label='train')\n",
        "plt.plot(val_acc_his, 'bv-', label='validation')\n",
        "plt.plot(test_acc_his, 'g+-', label='test')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Step')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}